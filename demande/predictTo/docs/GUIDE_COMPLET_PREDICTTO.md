# ğŸ“š Guide Complet - SystÃ¨me XGBoost de PrÃ©diction TO

## ğŸ¯ Introduction

Ce guide vous accompagne de l'installation Ã  l'utilisation en production du systÃ¨me de prÃ©diction XGBoost.

---

## ğŸ“¦ Fichiers CrÃ©Ã©s

### Scripts Python (5 fichiers)

| Fichier | Description | Utilisation |
|---------|-------------|-------------|
| `xgboost_train_model.py` | Script principal d'entraÃ®nement | `python xgboost_train_model.py` |
| `xgboost_predict_example.py` | Exemple de prÃ©diction | `python xgboost_predict_example.py` |
| `test_xgboost_setup.py` | Validation de l'environnement | `python test_xgboost_setup.py` |
| `load_model_from_azure.py` | Gestion modÃ¨les Azure | `python load_model_from_azure.py --list` |

### Documentation (4 fichiers)

| Fichier | Contenu |
|---------|---------|
| `docs/XGBOOST_TRAINING_DOC.md` | Documentation technique complÃ¨te (600+ lignes) |
| `README_XGBOOST.md` | Guide Quick Start |
| `RECAP_XGBOOST.md` | RÃ©sumÃ© des fonctionnalitÃ©s |
| `GUIDE_COMPLET_XGBOOST.md` | Ce fichier |

### Configuration (2 fichiers)

| Fichier | Description |
|---------|-------------|
| `config_xgboost.yaml` | Configuration paramÃ©trable |
| `requirements_xgboost.txt` | DÃ©pendances Python |

---

## ğŸš€ Installation ComplÃ¨te

### Ã‰tape 1 : Installer les DÃ©pendances

```bash
cd demande

# Installation des packages Python
pip install -r requirements_xgboost.txt
```

### Ã‰tape 2 : Configurer Azure (Optionnel)

```bash
# Option 1 : Variable d'environnement
export AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=VOTRE_COMPTE;AccountKey=VOTRE_CLE;EndpointSuffix=core.windows.net"

# Option 2 : Fichier .env (nÃ©cessite python-dotenv)
echo 'AZURE_STORAGE_CONNECTION_STRING="..."' > .env
```

### Ã‰tape 3 : VÃ©rifier l'Installation

```bash
python test_xgboost_setup.py
```

**Sortie attendue:**
```
âœ… CONFIGURATION VALIDE
   Vous pouvez lancer l'entraÃ®nement avec:
   python xgboost_train_model.py
```

---

## ğŸ“Š Workflow Complet

### 1ï¸âƒ£ EntraÃ®nement Initial

```bash
# Avec configuration par dÃ©faut
python xgboost_train_model.py

# Avec configuration personnalisÃ©e
python xgboost_train_model.py --config ma_config.yaml

# Sans sauvegarde Azure
python xgboost_train_model.py --no-azure
```

**RÃ©sultats gÃ©nÃ©rÃ©s:**
- `results/models/xgb_to_predictor.joblib`
- `results/models/xgb_scaler.joblib`
- `results/models/feature_columns.txt`
- `results/xgb_scatter_plot.png`
- `results/xgb_feature_importance.png`
- `xgboost_training.log`

### 2ï¸âƒ£ VÃ©rification des Performances

```bash
# VÃ©rifier les logs
tail -f xgboost_training.log

# Ouvrir les graphiques
open results/xgb_scatter_plot.png
open results/xgb_feature_importance.png
```

**MÃ©triques dans les logs:**
```
ğŸ“Š MÃ‰TRIQUES FINALES:
   Train MAE: 0.0450
   Train RÂ²:  0.8900
   Test MAE:  0.0560
   Test RÂ²:   0.8265
```

### 3ï¸âƒ£ Utilisation du ModÃ¨le Local

```bash
# Exemple de prÃ©diction
python xgboost_predict_example.py
```

**Sortie:**
```
âœ… PRÃ‰DICTION : TO final = 0.7234 (72.34%)

ğŸ“ˆ Analyse:
   TO actuel (J-8): 0.6900 (69.00%)
   TO prÃ©dit (J-0): 0.7234 (72.34%)
   Ã‰volution: +0.0334 (+4.84%)
   ğŸ“Š Tendance: MontÃ©e attendue
```

### 4ï¸âƒ£ Gestion Azure Blob Storage

```bash
# Lister les modÃ¨les disponibles
python load_model_from_azure.py --list

# TÃ©lÃ©charger le dernier modÃ¨le
python load_model_from_azure.py --download latest

# TÃ©lÃ©charger un modÃ¨le spÃ©cifique
python load_model_from_azure.py --download 20241216_143025

# TÃ©lÃ©charger dans un rÃ©pertoire personnalisÃ©
python load_model_from_azure.py --download latest --output mon_dossier
```

---

## âš™ï¸ Configuration AvancÃ©e

### Personnalisation via YAML

**Ã‰ditez `config_xgboost.yaml`:**

```yaml
# Modifier les hyperparamÃ¨tres
model:
  n_estimators: 800        # Plus d'arbres
  learning_rate: 0.03      # Apprentissage plus lent
  max_depth: 9             # Arbres plus profonds

# Changer l'horizon de prÃ©diction
prediction:
  horizon: 14              # PrÃ©dire Ã  J+14

# DÃ©sactiver Azure
azure:
  save_to_blob: false
```

**Puis:**
```bash
python xgboost_train_model.py --config config_xgboost.yaml
```

### Personnalisation par Code

```python
from xgboost_train_model import XGBoostOccupancyPredictor

config = {
    'clustering_results_path': 'mes_donnees/clustering.csv',
    'indicateurs_path': 'mes_donnees/indicateurs.csv',
    'prediction_horizon': 14,
    'model_params': {
        'n_estimators': 1000,
        'max_depth': 10,
        # ...
    }
}

predictor = XGBoostOccupancyPredictor(config)
# ... pipeline complet
```

---

## ğŸ” Utilisation en Production

### ScÃ©nario 1 : PrÃ©diction Unique

```python
import joblib
from xgboost_predict_example import compute_pm_features

# Charger le modÃ¨le
model = joblib.load("results/models/xgb_to_predictor.joblib")
scaler = joblib.load("results/models/xgb_scaler.joblib")

# PrÃ©parer les donnÃ©es
to_series = [0.05, 0.06, ..., 0.69]  # 53 valeurs
pm_series = [120, 121, ..., 125]     # 53 valeurs

# CrÃ©er le vecteur de features
row_dict = {}
for i, val in enumerate(range(60, 7, -1)):
    row_dict[f"J-{val}"] = to_series[i]

row_dict.update(compute_pm_features(pm_series))
row_dict.update({
    "cluster": 3,
    "month": 8,
    "dayofweek": 4,
    "nb_observations": 53
})

# PrÃ©dire
row_df = pd.DataFrame([row_dict])
row_scaled = scaler.transform(row_df)
prediction = model.predict(row_scaled)[0]
```

### ScÃ©nario 2 : PrÃ©dictions en Batch

```python
import pandas as pd

# Charger un fichier de nouvelles donnÃ©es
new_data = pd.read_csv("nouvelles_donnees.csv")

# Appliquer le pipeline de prÃ©paration
predictor = XGBoostOccupancyPredictor(config)
X_new = predictor.prepare_features(new_data)

# Normaliser
X_new_scaled = predictor.scaler.transform(X_new)

# PrÃ©dire
predictions = predictor.model.predict(X_new_scaled)

# Sauvegarder les rÃ©sultats
results_df = pd.DataFrame({
    'stay_date': new_data['stay_date'],
    'predicted_to': predictions
})
results_df.to_csv("predictions.csv", index=False)
```

### ScÃ©nario 3 : API REST (Flask)

```python
from flask import Flask, request, jsonify
from xgboost_predict_example import load_model_artifacts, predict_to

app = Flask(__name__)

# Charger le modÃ¨le au dÃ©marrage
model, scaler, feature_cols = load_model_artifacts()

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    
    prediction = predict_to(
        model=model,
        scaler=scaler,
        feature_cols=feature_cols,
        to_series=data['to_series'],
        pm_series=data['pm_series'],
        cluster=data['cluster'],
        month=data['month'],
        dayofweek=data['dayofweek']
    )
    
    return jsonify({'predicted_to': float(prediction)})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

---

## ğŸ”„ Workflow de RÃ©entraÃ®nement

### Quand RÃ©entraÃ®ner ?

- âœ… **Mensuel** : Routine recommandÃ©e
- âš ï¸ **Ad-hoc** si :
  - Nouvelles donnÃ©es > 10% du volume actuel
  - Performance dÃ©gradÃ©e (MAE > 0.07)
  - Changement de saisonnalitÃ©
  - Feedback mÃ©tier

### ProcÃ©dure de RÃ©entraÃ®nement

```bash
# 1. VÃ©rifier les nouvelles donnÃ©es
python test_xgboost_setup.py

# 2. Lancer l'entraÃ®nement
python xgboost_train_model.py

# 3. Comparer les performances
# Ancienne version
echo "Ancien modÃ¨le: MAE = 0.0560, RÂ² = 0.8265"

# Nouvelle version (dans les logs)
tail xgboost_training.log

# 4. Si meilleur : dÃ©ployer
python load_model_from_azure.py --download latest

# 5. Tester en production
python xgboost_predict_example.py
```

---

## ğŸ› ï¸ Maintenance

### Monitoring des Performances

CrÃ©ez un fichier `monitor_model.py`:

```python
import pandas as pd
import joblib
from sklearn.metrics import mean_absolute_error

# Charger le modÃ¨le
model = joblib.load("results/models/xgb_to_predictor.joblib")
scaler = joblib.load("results/models/xgb_scaler.joblib")

# Charger les vraies valeurs vs prÃ©dictions
real_data = pd.read_csv("production_data.csv")

# Comparer
mae = mean_absolute_error(real_data['real_to'], real_data['predicted_to'])

# Alerter si performance dÃ©gradÃ©e
if mae > 0.07:
    print(f"âš ï¸  ALERTE : Performance dÃ©gradÃ©e (MAE = {mae:.4f})")
    # Envoyer une notification...
```

### Optimisation des HyperparamÃ¨tres

```python
from sklearn.model_selection import GridSearchCV
import xgboost as xgb

param_grid = {
    'n_estimators': [400, 600, 800],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [5, 7, 9],
    'subsample': [0.8, 0.9, 1.0]
}

xgb_model = xgb.XGBRegressor(random_state=42)

grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X_train, y_train)
print(f"Meilleurs params: {grid_search.best_params_}")
```

---

## ğŸ“Š Analyse des RÃ©sultats

### InterprÃ©ter le Scatter Plot

```
TO RÃ©el vs TO PrÃ©dit
â”‚
â”‚   Points au-dessus de la ligne â†’ Sous-estimation
â”‚   Points en-dessous â†’ Sur-estimation
â”‚   Points sur la ligne â†’ PrÃ©diction parfaite
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### InterprÃ©ter Feature Importance

- **J-8 (46%)** : Le TO Ã  J-8 est le meilleur prÃ©dicteur
- **J-9 (13%)** : Confirmation de la tendance rÃ©cente
- **cluster (8%)** : Le comportement type du groupe
- **Features PM (~3%)** : Impact du prix moyen

â¡ï¸ **Conclusion:** Les 7-8 derniers jours de TO sont critiques

---

## ğŸ› Troubleshooting Complet

### ProblÃ¨me : "ModuleNotFoundError"

```bash
# RÃ©installer toutes les dÃ©pendances
pip install -r requirements_xgboost.txt --force-reinstall
```

### ProblÃ¨me : "Fichier non trouvÃ©"

```bash
# VÃ©rifier la structure
python test_xgboost_setup.py

# VÃ©rifier manuellement
ls -la results/clustering_results.csv
ls -la data/Indicateurs.csv
```

### ProblÃ¨me : "Azure Blob Error"

```bash
# Test de connexion
python -c "from azure.storage.blob import BlobServiceClient; print('âœ… Azure OK')"

# VÃ©rifier la connection string
env | grep AZURE

# Tester sans Azure
python xgboost_train_model.py --no-azure
```

### ProblÃ¨me : "Mauvaise Performance (RÂ² < 0.70)"

**Diagnostic:**
1. VÃ©rifier la qualitÃ© des donnÃ©es
2. Analyser les outliers
3. VÃ©rifier la distribution train/test
4. Augmenter `n_estimators`

**Actions:**
```python
# Analyser les rÃ©sidus
residuals = y_test - y_pred
plt.hist(residuals, bins=50)
plt.show()

# Identifier les pires prÃ©dictions
worst = pd.DataFrame({
    'real': y_test,
    'pred': y_pred,
    'error': abs(y_test - y_pred)
}).sort_values('error', ascending=False).head(10)
```

---

## ğŸ“ˆ Cas d'Usage Pratiques

### Use Case 1 : PrÃ©diction pour demain

```python
from xgboost_predict_example import load_model_artifacts, predict_to

# Charger le modÃ¨le
model, scaler, features = load_model_artifacts()

# DonnÃ©es du jour
to_aujourd_hui = [...]  # TO de J-60 Ã  J-8
pm_aujourd_hui = [...]  # PM de J-60 Ã  J-8

# PrÃ©diction
to_predit = predict_to(
    model, scaler, features,
    to_aujourd_hui, pm_aujourd_hui,
    cluster=3, month=12, dayofweek=2
)

print(f"TO prÃ©dit pour demain: {to_predit*100:.1f}%")
```

### Use Case 2 : Analyse de SensibilitÃ©

```python
# Test de diffÃ©rents clusters
for cluster in range(7):
    pred = predict_to(..., cluster=cluster, ...)
    print(f"Cluster {cluster}: {pred:.3f}")

# Test de diffÃ©rents mois
for month in range(1, 13):
    pred = predict_to(..., month=month, ...)
    print(f"Mois {month}: {pred:.3f}")
```

### Use Case 3 : Batch Processing

```python
# Charger plusieurs rÃ©servations
reservations = pd.read_csv("reservations_to_predict.csv")

predictions = []
for idx, row in reservations.iterrows():
    pred = predict_to(
        model, scaler, features,
        row['to_series'], row['pm_series'],
        row['cluster'], row['month'], row['dayofweek']
    )
    predictions.append(pred)

reservations['predicted_to'] = predictions
reservations.to_csv("predictions_batch.csv")
```

---

## ğŸ” SÃ©curitÃ© et Bonnes Pratiques

### Variables d'Environnement

**Ne JAMAIS commit:**
- `.env`
- Connection strings
- ClÃ©s API

**Ã€ faire:**
```bash
# Ajouter au .gitignore
echo ".env" >> .gitignore
echo "*.log" >> .gitignore
```

### Gestion des Versions

**Versionner:**
- âœ… Scripts Python
- âœ… Configuration YAML
- âœ… Documentation
- âœ… Requirements.txt

**Ne PAS versionner:**
- âŒ ModÃ¨les (.joblib)
- âŒ Logs
- âŒ Fichiers temporaires
- âŒ Credentials

### Backup

```bash
# Sauvegarder pÃ©riodiquement
cp results/models/*.joblib backups/$(date +%Y%m%d)/
```

---

## ğŸ“… Planning de Maintenance

### Hebdomadaire
- [ ] VÃ©rifier les logs (`xgboost_training.log`)
- [ ] Monitorer les performances en production

### Mensuel
- [ ] RÃ©entraÃ®ner le modÃ¨le
- [ ] Comparer avec version prÃ©cÃ©dente
- [ ] Mettre Ã  jour la documentation si changements

### Trimestriel
- [ ] Audit complet du code
- [ ] Optimisation des hyperparamÃ¨tres
- [ ] Revue des features (ajout/suppression)

---

## ğŸ“ Formation de l'Ã‰quipe

### Pour les Data Scientists

**Lire:**
1. `docs/XGBOOST_TRAINING_DOC.md` (technique)
2. Code source de `xgboost_train_model.py`
3. Notebook original `test_xgboost_prediction.ipynb`

**Pratiquer:**
1. Lancer un entraÃ®nement complet
2. Modifier les hyperparamÃ¨tres
3. Ajouter une nouvelle feature

### Pour les DevOps

**Lire:**
1. `README_XGBOOST.md` (deployment)
2. Section Azure de la doc technique

**Pratiquer:**
1. Configurer Azure Blob Storage
2. Automatiser le rÃ©entraÃ®nement (cron/airflow)
3. Mettre en place le monitoring

### Pour les Utilisateurs MÃ©tier

**Lire:**
1. `RECAP_XGBOOST.md` (overview)
2. Section "MÃ©triques" de la doc technique

**Utiliser:**
1. `xgboost_predict_example.py` pour tester
2. InterprÃ©ter les rÃ©sultats (MAE, RÂ²)

---

## ğŸ¯ Checklist de DÃ©ploiement

### Avant le Premier Lancement

- [ ] Installation des dÃ©pendances vÃ©rifiÃ©e
- [ ] Fichiers de donnÃ©es prÃ©sents et validÃ©s
- [ ] Configuration Azure testÃ©e
- [ ] `test_xgboost_setup.py` exÃ©cutÃ© avec succÃ¨s

### AprÃ¨s l'EntraÃ®nement

- [ ] Logs vÃ©rifiÃ©s (pas d'erreurs)
- [ ] MÃ©triques satisfaisantes (RÂ² > 0.75)
- [ ] Graphiques gÃ©nÃ©rÃ©s et cohÃ©rents
- [ ] ModÃ¨le sauvegardÃ© (local + Azure)

### Avant la Production

- [ ] Test de prÃ©diction rÃ©ussi
- [ ] Validation mÃ©tier des prÃ©dictions
- [ ] Documentation Ã  jour
- [ ] Plan de monitoring en place

---

## ğŸ“š RÃ©fÃ©rences

### Documentation Interne
- ğŸ“– [Documentation Technique ComplÃ¨te](docs/XGBOOST_TRAINING_DOC.md)
- ğŸ“„ [Quick Start Guide](README_XGBOOST.md)
- ğŸ“ [RÃ©sumÃ© des FonctionnalitÃ©s](RECAP_XGBOOST.md)

### Documentation Externe
- [XGBoost Official Docs](https://xgboost.readthedocs.io/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Azure Blob Storage Python SDK](https://docs.microsoft.com/azure/storage/blobs/storage-quickstart-blobs-python)

---

## ğŸ’¡ Astuces et Conseils

### Performance

```python
# Utiliser tous les CPU
'n_jobs': -1

# Augmenter le learning rate si overfitting
'learning_rate': 0.1

# RÃ©gularisation plus forte
'reg_lambda': 2.0
```

### Debugging

```python
# Activer le mode verbose
import logging
logging.basicConfig(level=logging.DEBUG)

# VÃ©rifier les features
print(model.get_booster().feature_names)

# Analyser les prÃ©dictions
print(f"Min: {y_pred.min()}, Max: {y_pred.max()}")
```

### Optimisation

```python
# Cross-validation pour validation robuste
from sklearn.model_selection import cross_val_score

scores = cross_val_score(
    model, X, y, 
    cv=5, 
    scoring='neg_mean_absolute_error'
)
print(f"CV MAE: {-scores.mean():.4f} (+/- {scores.std():.4f})")
```

---

## ğŸ‰ Conclusion

Vous avez maintenant un systÃ¨me complet et professionnel pour :
- âœ… EntraÃ®ner un modÃ¨le XGBoost de prÃ©diction TO
- âœ… Sauvegarder dans Azure Blob Storage
- âœ… Faire des prÃ©dictions en production
- âœ… Monitorer et maintenir le systÃ¨me

**Bon travail ! ğŸš€**

---

**Version:** 1.0  
**DerniÃ¨re mise Ã  jour:** DÃ©cembre 2024  
**Contact:** Ã‰quipe Data Science

