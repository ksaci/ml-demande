# Guide d'utilisation du script batch `run_predictTo_batch.py`

## ğŸ“‹ Vue d'ensemble

Le script `run_predictTo_batch.py` permet d'entraÃ®ner automatiquement des modÃ¨les XGBoost pour un hÃ´tel donnÃ© avec plusieurs horizons de prÃ©diction en une seule commande.

## ğŸ¯ Horizons par dÃ©faut

Le script entraÃ®ne des modÃ¨les pour les horizons suivants :
- **J-59** : PrÃ©diction 59 jours Ã  l'avance (maximum possible)
- **J-45** : PrÃ©diction 45 jours Ã  l'avance
- **J-30** : PrÃ©diction 30 jours Ã  l'avance
- **J-21** : PrÃ©diction 21 jours Ã  l'avance
- **J-15** : PrÃ©diction 15 jours Ã  l'avance
- **J-10** : PrÃ©diction 10 jours Ã  l'avance
- **J-7** : PrÃ©diction 7 jours Ã  l'avance
- **J-5** : PrÃ©diction 5 jours Ã  l'avance
- **J-3** : PrÃ©diction 3 jours Ã  l'avance
- **J-1** : PrÃ©diction 1 jour Ã  l'avance
- **J-0** : PrÃ©diction le jour mÃªme

**Note** : L'horizon maximum est J-59 car les donnÃ©es PM/TO vont jusqu'Ã  J-60. Pour prÃ©dire Ã  J-59, on utilise les donnÃ©es de J-60.

## ğŸš€ Utilisation

### Commande de base

```bash
cd predictTo
python run_predictTo_batch.py --hotel D09
```

Cette commande va :
1. EntraÃ®ner 11 modÃ¨les (un pour chaque horizon : J-59, J-45, J-30, J-21, J-15, J-10, J-7, J-5, J-3, J-1, J-0)
2. Sauvegarder localement dans `results/D09/{hotel}/J-{horizon}/`
3. Uploader dans Azure Blob Storage : `ml-models/predictTo/{hotel}/J-{horizon}/`

### Options disponibles

#### 1. SpÃ©cifier un hÃ´tel (obligatoire)
```bash
python run_predictTo_batch.py --hotel D09
python run_predictTo_batch.py --hotel 6N8
```

#### 2. EntraÃ®ner uniquement certains horizons
```bash
# Seulement J-7, J-14 et J-30
python run_predictTo_batch.py --hotel D09 --horizons 7 14 30

# Seulement les horizons courts
python run_predictTo_batch.py --hotel D09 --horizons 1 3 5 7
```

#### 3. DÃ©sactiver la sauvegarde Azure
```bash
python run_predictTo_batch.py --hotel D09 --no-azure
```

#### 4. Activer la recherche d'hyperparamÃ¨tres
```bash
# âš ï¸ ATTENTION : cela va multiplier le temps d'entraÃ®nement par ~10-15x
python run_predictTo_batch.py --hotel D09 --search-hyperparams
```

#### 5. Utiliser un fichier de configuration personnalisÃ©
```bash
python run_predictTo_batch.py --hotel D09 --config config_custom.yaml
```

### Combinaisons d'options

```bash
# EntraÃ®nement rapide sans Azure pour horizons courts
python run_predictTo_batch.py --hotel D09 --horizons 1 3 5 7 --no-azure

# EntraÃ®nement complet avec recherche d'hyperparamÃ¨tres
python run_predictTo_batch.py --hotel 6N8 --search-hyperparams

# Test sur un seul horizon
python run_predictTo_batch.py --hotel D09 --horizons 7
```

## ğŸ“ Structure de sortie

### Locale
```
results/D09/
â””â”€â”€ D09/                    # Code de l'hÃ´tel
    â”œâ”€â”€ J-60/
    â”‚   â”œâ”€â”€ models/
    â”‚   â”‚   â”œâ”€â”€ xgb_to_predictor.joblib
    â”‚   â”‚   â”œâ”€â”€ xgb_scaler.joblib
    â”‚   â”‚   â””â”€â”€ feature_columns.txt
    â”‚   â”œâ”€â”€ xgb_scatter_plot.png
    â”‚   â”œâ”€â”€ xgb_feature_importance.png
    â”‚   â”œâ”€â”€ training_data_before_scaling.csv
    â”‚   â””â”€â”€ test_predictions.csv
    â”œâ”€â”€ J-45/
    â”œâ”€â”€ J-30/
    â”œâ”€â”€ J-21/
    â”œâ”€â”€ J-15/
    â”œâ”€â”€ J-10/
    â”œâ”€â”€ J-7/
    â”œâ”€â”€ J-5/
    â”œâ”€â”€ J-3/
    â”œâ”€â”€ J-1/
    â””â”€â”€ J-0/
```

### Azure Blob Storage (container `ml-models`)
```
ml-models/
â””â”€â”€ predictTo/
    â””â”€â”€ D09/                # Code de l'hÃ´tel
    â”œâ”€â”€ J-59/
    â”œâ”€â”€ J-45/
    â”œâ”€â”€ J-30/
    â”œâ”€â”€ J-21/
    â”œâ”€â”€ J-15/
    â”œâ”€â”€ J-10/
    â”œâ”€â”€ J-7/
    â”œâ”€â”€ J-5/
    â”œâ”€â”€ J-3/
    â”œâ”€â”€ J-1/
    â””â”€â”€ J-0/
```

## ğŸ“Š RÃ©sumÃ© de l'exÃ©cution

Ã€ la fin de l'exÃ©cution, le script affiche un rÃ©sumÃ© dÃ©taillÃ© :

```
================================================================================
ğŸ“Š RÃ‰SUMÃ‰ DU BATCH TRAINING
================================================================================
HÃ´tel: D09
Total de modÃ¨les: 11
âœ… SuccÃ¨s: 11
âŒ Erreurs: 0
â±ï¸  DurÃ©e totale: 45.32 minutes (2719.20 secondes)

DÃ©tails par horizon:
--------------------------------------------------------------------------------
Horizon    Statut       DurÃ©e (s)    Test MAE     Test RÂ²     
--------------------------------------------------------------------------------
J-59       âœ… SuccÃ¨s    245.32       0.0234       0.8567      
J-45       âœ… SuccÃ¨s    238.45       0.0228       0.8612      
J-30       âœ… SuccÃ¨s    242.11       0.0221       0.8701      
J-21       âœ… SuccÃ¨s    239.87       0.0215       0.8765      
J-15       âœ… SuccÃ¨s    241.23       0.0208       0.8823      
J-10       âœ… SuccÃ¨s    243.56       0.0201       0.8891      
J-7        âœ… SuccÃ¨s    240.34       0.0195       0.8945      
J-5        âœ… SuccÃ¨s    238.92       0.0189       0.9012      
J-3        âœ… SuccÃ¨s    241.67       0.0183       0.9078      
J-1        âœ… SuccÃ¨s    239.11       0.0177       0.9145      
J-0        âœ… SuccÃ¨s    238.45       0.0171       0.9201      
--------------------------------------------------------------------------------

================================================================================
âœ… BATCH TRAINING TERMINÃ‰ AVEC SUCCÃˆS
================================================================================
```

## ğŸ“ Logs

Les logs sont sauvegardÃ©s dans deux fichiers :
- `predictTo_batch.log` : Log du script batch principal
- `predictTo_training.log` : Logs dÃ©taillÃ©s de chaque entraÃ®nement

## â±ï¸ Temps d'exÃ©cution estimÃ©

### Sans recherche d'hyperparamÃ¨tres (par dÃ©faut)
- **Par horizon** : ~4-5 minutes
- **11 horizons** : ~45-55 minutes
- **Avec Azure** : +1-2 minutes

### Avec recherche d'hyperparamÃ¨tres (`--search-hyperparams`)
- **Par horizon** : ~30-45 minutes
- **11 horizons** : ~5-8 heures âš ï¸

## ğŸ”§ PrÃ©requis

1. **DonnÃ©es requises** :
   - RÃ©sultats de clustering : `../cluster/results/{hotel}/clustering_results.csv`
     - Le script charge automatiquement les donnÃ©es depuis `cluster/results/{hotel}/` quand `--hotel` est spÃ©cifiÃ©
     - Exemple pour D09 : `../cluster/results/D09/clustering_results.csv`
   - Indicateurs : `../data/D09/Indicateurs.csv`
   - Prix concurrents : `../data/D09/rateShopper.csv`

2. **Configuration Azure** (optionnel) :
   - Variable d'environnement : `AZURE_STORAGE_CONNECTION_STRING`
   - Container : `ml-models`

3. **DÃ©pendances Python** :
   ```bash
   pip install -r requirements_predictTo.txt
   ```

## âŒ Gestion des erreurs

Si un horizon Ã©choue :
- Le script continue avec les autres horizons
- L'erreur est loggÃ©e dans le fichier de log
- Le rÃ©sumÃ© final indique les horizons en erreur

Exemple avec erreurs :
```
âš ï¸  ERREURS DÃ‰TAILLÃ‰ES:
--------------------------------------------------------------------------------
Horizon J-45: FileNotFoundError: Data file not found
Horizon J-30: ValueError: Invalid data format
--------------------------------------------------------------------------------

âš ï¸  BATCH TRAINING TERMINÃ‰ AVEC 2 ERREUR(S)
```

## ğŸ’¡ Conseils d'utilisation

1. **Test rapide** : Commencez par un seul horizon pour vÃ©rifier que tout fonctionne
   ```bash
   python run_predictTo_batch.py --hotel D09 --horizons 7 --no-azure
   ```

2. **Production** : Utilisez les horizons par dÃ©faut avec Azure
   ```bash
   python run_predictTo_batch.py --hotel D09
   ```

3. **Optimisation** : Lancez la recherche d'hyperparamÃ¨tres sur un horizon reprÃ©sentatif (J-7 ou J-14), puis utilisez les meilleurs paramÃ¨tres dans `config_predictTo.yaml` pour tous les horizons
   ```bash
   # Ã‰tape 1 : Recherche sur J-7
   python predictTo_train_model.py --hotel D09 --horizon 7 --search-hyperparams
   
   # Ã‰tape 2 : Mettre Ã  jour config_predictTo.yaml avec les meilleurs params
   
   # Ã‰tape 3 : EntraÃ®ner tous les horizons avec les params optimisÃ©s
   python run_predictTo_batch.py --hotel D09
   ```

## ğŸ”— Voir aussi

- [Guide complet PredictTO](GUIDE_COMPLET_PREDICTTO.md)
- [Documentation de l'entraÃ®nement](PREDICTTO_TRAINING_DOC.md)
- [Documentation des features](features_documentation.md)

