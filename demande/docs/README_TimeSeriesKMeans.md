# ğŸ•’ TimeSeriesKMeans avec DTW - Guide d'Utilisation

## ğŸ“Š Changement Important : KMeans â†’ TimeSeriesKMeans

Le script a Ã©tÃ© mis Ã  jour pour utiliser **TimeSeriesKMeans** de la bibliothÃ¨que `tslearn` au lieu de KMeans classique de scikit-learn.

## ğŸ¯ Pourquoi TimeSeriesKMeans ?

### ProblÃ¨me avec KMeans classique

KMeans utilise la **distance euclidienne** qui n'est pas adaptÃ©e aux sÃ©ries temporelles :

```python
# Distance euclidienne : somme des carrÃ©s des diffÃ©rences point par point
distance = sqrt(sum((point1[i] - point2[i])^2))
```

**Limitations** :
- âŒ Ne gÃ¨re pas les dÃ©calages temporels
- âŒ Sensible aux variations d'Ã©chelle
- âŒ Ne capture pas les formes similaires

### Avantage de TimeSeriesKMeans avec DTW

**DTW (Dynamic Time Warping)** aligne les sÃ©ries temporelles de maniÃ¨re optimale :

```python
# DTW trouve le meilleur alignement entre deux courbes
# MÃªme si elles sont dÃ©calÃ©es ou de vitesses diffÃ©rentes
```

**Avantages** :
- âœ… GÃ¨re les dÃ©calages temporels
- âœ… Capture les formes similaires
- âœ… Plus robuste pour les sÃ©ries temporelles
- âœ… Meilleure qualitÃ© de clustering

## ğŸ“¦ Installation

```bash
pip install tslearn
```

## ğŸ”§ Modifications ApportÃ©es

### 1. Imports

**Avant** :
```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
```

**Maintenant** :
```python
from tslearn.clustering import TimeSeriesKMeans
from tslearn.preprocessing import TimeSeriesScalerMeanVariance
```

### 2. Format des DonnÃ©es

TimeSeriesKMeans attend un format 3D : `(n_samples, n_timestamps, n_features)`

**Conversion automatique** :
```python
# De (n_courbes, n_jours) Ã  (n_courbes, n_jours, 1)
data_3d = curves_df[feature_cols].values[:, :, np.newaxis]
```

### 3. Utilisation

#### Dans le script `prediction_cluster.py`

```python
# Clustering avec DTW (mÃ©trique par dÃ©faut)
clustering.perform_clustering(n_clusters=5, metric="dtw")

# Ou tester d'autres mÃ©triques :
clustering.perform_clustering(n_clusters=5, metric="euclidean")
clustering.perform_clustering(n_clusters=5, metric="softdtw")
```

#### Dans le notebook autonome

Tout le code est visible et modifiable :

```python
# Dans la cellule de clustering
ts_kmeans_model = TimeSeriesKMeans(
    n_clusters=5, 
    metric="dtw",      # DTW pour sÃ©ries temporelles
    random_state=42, 
    n_init=10,
    verbose=False
)
```

## ğŸ“ MÃ©triques Disponibles

### 1. **DTW (Dynamic Time Warping)** - RecommandÃ©
```python
metric="dtw"
```
- âœ… Meilleur pour les sÃ©ries temporelles
- âœ… GÃ¨re les dÃ©calages
- âš ï¸ Plus lent que euclidean

### 2. **Euclidean**
```python
metric="euclidean"
```
- âœ… Plus rapide
- âŒ Moins adaptÃ© aux sÃ©ries temporelles

### 3. **Soft-DTW**
```python
metric="softdtw"
```
- âœ… Version diffÃ©rentiable de DTW
- âœ… Bon compromis vitesse/qualitÃ©

## ğŸ¨ Exemple Visuel

### Avec KMeans classique (distance euclidienne)

```
Courbe A:  ___/â€¾â€¾â€¾â€¾\___
Courbe B:  __/â€¾â€¾â€¾â€¾\____  (lÃ©gÃ¨rement dÃ©calÃ©e)
         
Distance euclidienne : GRANDE (points ne s'alignent pas)
â†’ Clusters diffÃ©rents âŒ
```

### Avec TimeSeriesKMeans + DTW

```
Courbe A:  ___/â€¾â€¾â€¾â€¾\___
Courbe B:  __/â€¾â€¾â€¾â€¾\____
         
DTW aligne les courbes intelligemment
â†’ MÃªme cluster âœ…
```

## ğŸ“Š Impact sur les RÃ©sultats

Avec TimeSeriesKMeans + DTW, vous obtiendrez :

1. **Meilleurs clusters** : Courbes similaires regroupÃ©es ensemble
2. **Profils plus clairs** : "DerniÃ¨re minute" vs "AnticipÃ©" mieux sÃ©parÃ©s
3. **MÃ©triques amÃ©liorÃ©es** : Score de silhouette gÃ©nÃ©ralement plus Ã©levÃ©

## âš™ï¸ ParamÃ¨tres Ajustables

### Dans `prediction_cluster.py`

```python
# Changer la mÃ©trique
optimal_k = clustering.find_optimal_clusters(max_k=10, metric="dtw")
clustering.perform_clustering(n_clusters=optimal_k, metric="dtw")

# MÃ©triques disponibles
metrics = ["dtw", "euclidean", "softdtw"]
```

### Dans le notebook

Modifiez directement dans les cellules :

```python
# Cellule de recherche K optimal
for k in k_range:
    ts_kmeans = TimeSeriesKMeans(
        n_clusters=k, 
        metric="dtw",          # â­ Changez ici
        random_state=42, 
        n_init=5,
        verbose=False
    )
```

## ğŸš€ Performance

### Temps d'exÃ©cution

| MÃ©trique | Vitesse | QualitÃ© |
|----------|---------|---------|
| euclidean | âš¡âš¡âš¡ Rapide | â­â­ Moyenne |
| softdtw | âš¡âš¡ Moyen | â­â­â­ Bonne |
| **dtw** | âš¡ Lent | â­â­â­â­ **Excellente** |

**Recommandation** : Utilisez DTW pour l'analyse finale, euclidean pour les tests rapides.

## ğŸ“ Notes Techniques

### Format des donnÃ©es

```python
# Input attendu par TimeSeriesKMeans
shape: (n_samples, n_timestamps, n_features)
exemple: (5000, 61, 1)
         â†‘      â†‘   â†‘
         |      |   â””â”€ 1 feature (le To)
         |      â””â”€â”€â”€â”€â”€ 61 points (J-60 Ã  J)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5000 courbes
```

### Normalisation

`TimeSeriesScalerMeanVariance` normalise chaque sÃ©rie temporelle :
- Moyenne = 0
- Ã‰cart-type = 1

## ğŸ” DÃ©bogage

Si vous rencontrez des erreurs :

### Erreur : "Module 'tslearn' not found"
```bash
pip install tslearn
```

### Erreur : "Shape mismatch"
VÃ©rifiez que les donnÃ©es sont bien en 3D :
```python
print(scaled_curves.shape)  # Doit Ãªtre (n, timestamps, 1)
```

### DTW trop lent ?
RÃ©duisez les donnÃ©es ou utilisez `softdtw` :
```python
clustering.perform_clustering(n_clusters=5, metric="softdtw")
```

## ğŸ“š Ressources

- [tslearn documentation](https://tslearn.readthedocs.io/)
- [DTW expliquÃ©](https://en.wikipedia.org/wiki/Dynamic_time_warping)
- [TimeSeriesKMeans API](https://tslearn.readthedocs.io/en/stable/gen_modules/clustering/tslearn.clustering.TimeSeriesKMeans.html)

## âœ… Checklist

- [x] tslearn installÃ©
- [x] Script mis Ã  jour avec TimeSeriesKMeans
- [x] Notebook autonome mis Ã  jour
- [x] DTW comme mÃ©trique par dÃ©faut
- [x] Format 3D pour les donnÃ©es
- [x] Tests effectuÃ©s

---

**Version** : 2.0 (avec TimeSeriesKMeans)  
**Date** : Novembre 2025  
**MÃ©trique recommandÃ©e** : DTW

